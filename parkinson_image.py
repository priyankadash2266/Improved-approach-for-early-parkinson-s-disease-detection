# -*- coding: utf-8 -*-
"""Parkinson_Image.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t959CpotbytDkr4j9kqy-RQ83-Cj0wLP
"""

from google.colab import drive
drive.mount('/content/drive')

import warnings
warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np
import os
import cv2
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
import tensorflow as tf
import tensorflow.keras as k
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, AveragePooling2D, Flatten, Dropout

path_folder = "/content/drive/MyDrive/parkinsons_dataset"
class_name = os.listdir(path_folder)
class_name

path_folder = "/content/drive/MyDrive/parkinsons_dataset"
class_name = os.listdir(path_folder)
class_name.sort()
#class_name = class_name[:4] + class_name[20:23]
print(class_name)
image_data = []
label_data = []
count = 0
for folder in class_name:
    images = os.listdir(path_folder + "/" + folder)
    print("Loading Folder -- {} " .format(folder), "The Count of Classes ==> ",count)
    for img in images:
        image = cv2.imread(path_folder + "/" + folder + "/" + img)
        image = cv2.resize(image, (224, 224))

        image_data.append(image)
        label_data.append(count)
    count += 1
print("---- Done ----------- ")

data = np.array(image_data)
data = data.astype("float32")
data = data/255.0

label = np.array(label_data)

print(data.shape)

label_num = to_categorical(label, len(class_name))

x_img, y_img = shuffle(data, label_num)
x_train, x_test, y_train, y_test = train_test_split(x_img, y_img, train_size=0.8)

x_train.shape, y_train.shape, x_test.shape, y_test.shape

plt.figure(figsize=(10, 10))
for i in range(0, 25):
    plt.subplot(5, 5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(x_train[i])
    plt.title(class_name[np.argmax(y_train[i])])

model = k.models.Sequential()

model.add(k.layers.Conv2D(16, (5, 5), activation="relu", input_shape=(224, 224, 3), padding="same"))
model.add(k.layers.AveragePooling2D((2, 2)))

model.add(k.layers.Conv2D(32, (4, 4), activation="relu",  padding="same"))
# model.add(k.layers.BatchNormalization())
model.add(k.layers.AveragePooling2D((2, 2)))


model.add(k.layers.Conv2D(64, (3, 3), activation="relu", padding="same"))
model.add(k.layers.AveragePooling2D((2, 2)))

model.add(k.layers.Conv2D(128, (2, 2), activation="relu", padding="same"))
model.add(k.layers.MaxPool2D((2, 2)))

model.add(k.layers.Flatten())

model.add(k.layers.Dense(256, activation="relu"))
# model.add(k.layers.BatchNormalization())
model.add(k.layers.Dropout(0.5))

model.add(k.layers.Dense(32, activation="relu"))
model.add(k.layers.Dropout(0.2))

model.add(k.layers.Dense(len(class_name), activation="softmax"))

model.compile(optimizer="adam", loss=k.losses.CategoricalCrossentropy(), metrics=["accuracy"])

model.summary()

history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), validation_split=0.2)

plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

# accuracies
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Dense, Flatten, Dropout, Input
from tensorflow.keras.optimizers import Adam

# Define the input layer with the correct input shape
input_layer = Input(shape=(224, 224, 3))

# Load the VGG16 model with the base layers frozen and no top classification layers
vgg16_base = VGG16(weights='imagenet', include_top=False, input_tensor=input_layer)

# Freeze all layers in the VGG16 base model
for layer in vgg16_base.layers:
    layer.trainable = False

# Add custom layers on top of VGG16
x = Flatten()(vgg16_base.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
output_layer = Dense(len(class_name), activation='softmax')(x)

# Define the full model
model = Model(inputs=input_layer, outputs=output_layer)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    x_train, y_train,
    validation_data=(x_test, y_test),
    epochs=5,
    batch_size=32,
    verbose=1
)

model.save('Parkinson_vgg16_model.h5')

from tensorflow.keras.models import load_model

# Load the saved model
loaded_model = load_model('Parkinson_vgg16_model.h5')

plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.applications.vgg16 import preprocess_input

def preprocess_image(img_path):
    # Load the image with the target size of (224, 224)
    image = load_img(img_path, target_size=(224, 224))
    # Convert the image to an array
    image = img_to_array(image)
    # Expand dimensions to match the model input (1, 224, 224, 3)
    image = np.expand_dims(image, axis=0)
    # Preprocess the image for VGG16
    image = preprocess_input(image)
    return image

def predict_image(img_path, model):
    # Preprocess the image
    processed_image = preprocess_image(img_path)
    # Make a prediction
    predictions = model.predict(processed_image)
    # Get the class label with the highest probability
    predicted_class = np.argmax(predictions, axis=1)[0]
    class_name=['Normal', 'Parkinson']
    class_label = class_name[predicted_class]
    return class_label

# Example usage:
img_path = '/content/drive/MyDrive/parkinsons_dataset/normal/Mag_Images_005.png'
predicted_label = predict_image(img_path, loaded_model)
print(f"The model predicts: {predicted_label}")

