# -*- coding: utf-8 -*-
"""Parkinson's Disease Detection ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ia43a2yKf1E_QYk_s5YHRapD0c8hNMCD

# Importing related Libraries
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import os, sys
import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
import seaborn as sns
#import lux
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier

"""# Store the dataset into the Dataframe"""

# loading the data from csv file to a Pandas DataFrame
parkinsons_data = pd.read_csv('parkinsons.csv')

"""# DATA SET

### Check the shape of the dataframe
"""

# number of rows and columns in the dataframe
parkinsons_data.shape





"""### Check the Detail information of the dataframe"""

# getting more information about the dataset
parkinsons_data.info()

"""## Describe the entire dataset"""

# getting some statistical measures about the data
parkinsons_data.describe()

"""## Data Cleaning"""

# printing the first 5 rows of the dataframe
parkinsons_data.head()

"""### Checking for Null or None Values in columns"""

# checking for missing values in each column
parkinsons_data.isnull().sum()

"""### Target Variable(status)"""

# distribution of target Variable
parkinsons_data['status'].value_counts()

"""## 1  --> Parkinson's Positive

## 0 --> Healthy

### Grouping The Data
"""

temp=parkinsons_data["status"].value_counts()
temp_df=pd.DataFrame({'status':temp.index,'values':temp.values})
print(sns.barplot(x='status',y="values",data=temp_df))

sns.pairplot(parkinsons_data)

plt.figure(figsize=(20,20))
numeric_data = parkinsons_data.select_dtypes(include=np.number)
corr = numeric_data.corr()

sns.heatmap(corr, annot=True)

"""# Data Pre-Processing

### Separating the features & Target
"""

X = parkinsons_data.drop(columns=['name','status'], axis=1)
Y = parkinsons_data['status']

X.shape

Y

print(X)

print(Y)

"""## Data Standardization"""

#label balance
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from collections import Counter
print(Counter(Y))

#balance the labels
ros=RandomOverSampler()
X_ros,Y_ros=ros.fit_resample(X,Y)
print(Counter(Y_ros))

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler((-1,1))
X=scaler.fit_transform(X_ros)
Y=Y_ros



"""# Splitting of Train and the Test Data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=7)

print(X.shape, X_train.shape, X_test.shape)

"""# Model Training"""

from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score

list_met=[]
list_accuracy=[]

#logistic regression

from sklearn.linear_model import LogisticRegression

classifier = LogisticRegression(C=0.4,max_iter=1000,solver='liblinear')
lr=classifier.fit(X_train, Y_train)

Y_pred = classifier.predict(X_test)

accuracy_LR = accuracy_score(Y_test, Y_pred)

#Decision Tree

from sklearn.tree import DecisionTreeClassifier

classifier2 = DecisionTreeClassifier(random_state=10)
dt=classifier2.fit(X_train, Y_train)

Y_pred2 = classifier2.predict(X_test)

accuracy_DT = accuracy_score(Y_test, Y_pred2)

#Random forest criteria information gain

from sklearn.ensemble import RandomForestClassifier

classifier3 = RandomForestClassifier(random_state=14)
rfi=classifier3.fit(X_train, Y_train)

Y_pred3 = classifier3.predict(X_test)

accuracy_RFI = accuracy_score(Y_test, Y_pred3)

#Gaussian Navis Bayes

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()
gnb = gnb.fit(X_train, Y_train)

pred_gnb = gnb.predict(X_test)

accuracy_GNB = accuracy_score(Y_test, pred_gnb)

#Bernoulli navis Bayes

from sklearn.naive_bayes import BernoulliNB

model = BernoulliNB()
bnb=model.fit(X_train, Y_train)

preb_bnb = model.predict(X_test)

accuracy_BNB = accuracy_score(Y_test, preb_bnb)

model_xg=XGBClassifier()
model_xg.fit(X_train, Y_train)

Y_pred=model_xg.predict(X_test)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(Y_test, model_xg.predict(X_test))

from sklearn.metrics import f1_score

from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report,accuracy_score

from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report, accuracy_score

def plot_roc(model, x_test, y_test):

    probabilities = model.predict_proba(np.array(x_test))
    predictions = probabilities
    fpr, tpr, threshold = roc_curve(y_test, predictions[:,1])
    roc_auc = auc(fpr, tpr)

    plt.title('Reciver Operation Characteistics')
    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' %roc_auc)
    plt.legend(loc='lower right')
    plt.plot([0, 1], [0, 1], 'r--')
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    plt.ylabel('True Positive Rate')
    plt.xlabel('False positive Rate')
    plt.show()

"""plot_roc(model_xg, x_test, y_test)"""

plot_roc(model_xg, X_test, Y_test)

#input_data=(116.682,131.111,111.555,0.0105,0.00009,0.00544,0.00781,0.01633,0.05233,0.482,0.02757,0.03858,0.0359,0.0827,0.01309,20.651,0.429895,0.825288,-4.443179,0.311173,2.342259,0.332634
#)
input_data=(115.38,123.109,108.634,0.00332,0.00003,0.0016,0.00199,0.0048,0.01503,0.137,0.00812,0.00933,0.01133,0.02436,0.00401,26.005,0.405991,0.761255,-5.966779,0.197938,1.974857,0.184067)
input_data_as_numpy_array=np.asarray(input_data)
input_data_reshaped=input_data_as_numpy_array.reshape(1,-1)

std_data=scaler.transform(input_data_reshaped)
prediction=classifier3.predict(std_data)
if prediction==1:
    print("The person is suffering from parkinson disease")
else:
    print("This person is Healthy")
print(prediction)

